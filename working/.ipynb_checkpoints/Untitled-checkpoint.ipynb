{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Friday 20th May\n",
    "\n",
    "@author: Liz\n",
    "\n",
    "Date:   20/05/2016\n",
    "Verion: 1\n",
    "\n",
    "Inputs:  Price data \n",
    "outputs: DataFrame with chained index for all time periods\n",
    "changes - \n",
    "    added updated aggregation code\n",
    "    \n",
    "\"\"\"\n",
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import gmean \n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import os\n",
    "\n",
    "from scipy.stats import gmean \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "\n",
    "try:\n",
    "    os.remove(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/price_indices/CLIPweek2014.csv\")\n",
    "    os.remove(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/price_indices/CLIPweek2015.csv\")\n",
    "    os.remove(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/price_indices/CLIPweek2016.csv\")\n",
    "except:\n",
    "    pass\n",
    "#%%\n",
    "#Import Dataset\n",
    "#\n",
    "#os.chdir('D:/webscraped/New_Data')\n",
    "\n",
    "\n",
    "#This function sets the neccesary dataframe and removes empty prices\n",
    "def man(data,datevar):\n",
    "    tidata = pd.DataFrame()\n",
    "    #create dummy variable for store and offer type\n",
    "    shops = pd.get_dummies(data[\"store\"])\n",
    "    offercat = pd.get_dummies(data[\"offer_cat\"])\n",
    "    tidata[\"product_name\"]=data[\"idvar\"]\n",
    "    tidata[\"ons_item_name\"]=data[\"ons_item_name\"]\n",
    "    #set freq variable\n",
    "    tidata[\"monthday\"] = data[datevar]\n",
    "    #set price type\n",
    "    tidata[\"price\"] = data[\"item_price_num\"]\n",
    "    #remove 0 or non-numeric prices\n",
    "    tidata = tidata[np.isfinite(tidata['price'])]\n",
    "    #group together the dataframe for later use\n",
    "    tidata = pd.concat([tidata,shops,offercat],axis=1)\n",
    "    zscore = lambda x: gmean(x) # Note that it does not reference anything outside of 'x' and for transform 'x' is one column.\n",
    "    tidata[\"price\"]=tidata.groupby(['product_name','monthday'])[\"price\"].transform(zscore)\n",
    "    print(tidata.head(2))\n",
    "    tidata=tidata.drop_duplicates([\"product_name\",\"monthday\"])\n",
    "    print(len(tidata))\n",
    "    return tidata\n",
    "\n",
    "#The basetree function takes a sub-set of the data to the base month. reduces the dataframe to the varaibles that will be used within the clustering step of the CLIP, and uses DBScan clustering on this data.\n",
    "# It then uses the DBScan assignments of clusters as training data within a decision tree classifier to find the underlying structure of the clusters.\n",
    "#This returns the decision tree\n",
    "def basetree(data, basedate):\n",
    "    #just look at baseperiod\n",
    "    data2 = data[data[\"monthday\"].astype(int)==basedate]\n",
    "    data3 = data2\n",
    "    #reduce dataframe to the variables that will be used within the dbscan clustering (price is included here)\n",
    "    del data3[\"ons_item_name\"]\n",
    "    del data3[\"product_name\"]\n",
    "    del data3[\"monthday\"]    \n",
    "    #remove duplicates so that clustering is only on unique products. This stops grouping togethers of the same product\n",
    "    data3 = data3.drop_duplicates()\n",
    "    data5 = np.array(data3)\n",
    "    #run dbscan clustering\n",
    "#    print(\"len_unique_prod_base\")\n",
    "#this seems to work well! min_bin_freq = 2, clust = True, min_sample_lead = 5\n",
    "    ward = MeanShift(cluster_all=True, n_jobs=-1).fit(data5)\n",
    "\n",
    "    dt = DecisionTreeClassifier(criterion = \"gini\", min_samples_leaf=10)\n",
    "    data4 = data3\n",
    "    #criterion = \"entropy\",\n",
    "    #set up decision tree clustering on the same data used for the dbscan clustering minus price. Price is removed so that price can vary between clusters over time.\n",
    "    del data4[\"price\"]\n",
    "    #fit decision tree clusters\n",
    "    dt.fit(np.array(data4),ward.labels_+1)\n",
    "    # return decision tree\n",
    "#    print(dt.n_classes_)\n",
    "    return dt\n",
    "#algorithm  auto \n",
    "#The get_lineage function determines the underlying structure of the decision tree computed by the basetree function. Returning a list of rules which make up product classification rules\n",
    "def get_lineage(tree, feature_names):\n",
    "     left      = tree.tree_.children_left\n",
    "     right     = tree.tree_.children_right\n",
    "     threshold = tree.tree_.threshold\n",
    "     features  = [feature_names[i] for i in tree.tree_.feature]\n",
    "\n",
    "     # get ids of child nodes\n",
    "     idx = np.argwhere(left == -1)[:,0]     \n",
    "\n",
    "     def recurse(left, right, child, lineage=None):          \n",
    "          if lineage is None:\n",
    "               lineage = []\n",
    "          if child in left:\n",
    "               parent = np.where(left == child)[0].item()\n",
    "               split = 'l'\n",
    "          else:\n",
    "               parent = np.where(right == child)[0].item()\n",
    "               split = 'r'\n",
    "\n",
    "          lineage.append((parent, split, threshold[parent], features[parent]))\n",
    "\n",
    "          if parent == 0:\n",
    "               lineage.reverse()\n",
    "               return lineage\n",
    "          else:\n",
    "               return recurse(left, right, parent, lineage)\n",
    "     results = []\n",
    "     for child in idx:\n",
    "          for node in recurse(left, right, child):\n",
    "               results.append(node)\n",
    "     return results\n",
    "\n",
    "#the clus splits the data by the rules uncovered in get_lineage above'e'\n",
    "def clus(data, choice):\n",
    "    for i in range(0,len(choice)):\n",
    "        if choice.iat[i,1] == \"l\":\n",
    "            data = data[data[choice.iat[i,3]]<choice.iat[i,2]]\n",
    "        else:\n",
    "            data = data[data[choice.iat[i,3]]>choice.iat[i,2]]\n",
    "    return data\n",
    "\n",
    "#the thes function applies the decision tree to all time periods\n",
    "#function to apply the desision tree to the data by time period\n",
    "def thes(the,fulldata,data):\n",
    "    results=pd.DataFrame()\n",
    "    cluss=pd.DataFrame()\n",
    "    for i in range(0,(len(the))):\n",
    "        if i == len(the)-1:\n",
    "            clust = data.loc[the[i]:]\n",
    "            cluss = clus(fulldata, clust)\n",
    "            cluss[\"cluster\"]=i\n",
    "            results = results.append(cluss)\n",
    "        elif i != (len(the)-1):\n",
    "            clust = data.loc[the[i]:the[i+1]-1]\n",
    "            cluss = clus(fulldata, clust)\n",
    "            cluss[\"cluster\"]=i\n",
    "            results = results.append(cluss)\n",
    "    return results\n",
    "\n",
    "#The baseclust function applies clus and thes to the appropriate time periods (every month separately) then returns the data with the related classifications from the decision tree rules\n",
    "#The baseclust function applies clus and thes to the appropriate time periods (every month separately) then returns the data with the related classifications from the decision tree rules\n",
    "def baseclust(bt, data,basedate):\n",
    "    #take a subset of basedate data\n",
    "    fulldata = data[data[\"monthday\"].astype(int)==basedate]\n",
    "    #set up dataframe without period variable\n",
    "    del fulldata[\"monthday\"]\n",
    "    fulldata = fulldata.reset_index()\n",
    "    fulldata = fulldata.drop(\"index\",1)\n",
    "    #get structure of the decision tree in a table\n",
    "    structure = get_lineage(bt, fulldata.columns[1:])\n",
    "    #put structure of the decision tree in a dataframe\n",
    "    structure=pd.DataFrame(structure,columns=(\"level\",\"dir\",\"value\",\"var\"))\n",
    "    return structure\n",
    "\n",
    "def applydecisiontree(data,date,structure):\n",
    "    #take subset of data for date of interest\n",
    "    fulldata = data[data[\"monthday\"].astype(int)==date]\n",
    "    #set up dataframe how you want it\n",
    "    fulldata = fulldata.drop(\"monthday\",1)\n",
    "    fulldata = fulldata.reset_index()\n",
    "    fulldata = fulldata.drop(\"index\",1)\n",
    "    #find index numbers for the start of each cluster within the structure of the dataframe. Found in the baseclust\n",
    "    the = np.where(structure[\"level\"]==0)[0]\n",
    "    del structure[\"Unnamed: 0\"]\n",
    "    #run the structure of the decision tree classifier (calculated on the data for the base period) over the new data for the date of interest \n",
    "    results = thes(the,fulldata,structure)\n",
    "    #print(baseclust)\n",
    "    return results\n",
    "\n",
    "# \"Unnamed: 0\",\"sainsbury\",\"tesco\",\"waitrose\",\"Discount\",\"For\",\"add more\",\"prod_no\",\"cluster\"\n",
    "\n",
    "#The geobase function takes the data returned from the baseclust function for the basemonth which contains the clustering assignments. Then calcualtes the geometric mean of each cluster, and returns a table of the clusters and there related geometric means.\n",
    "def geobase(results):\n",
    "    from scipy.stats import gmean  \n",
    "    #group by clusters\n",
    "    grouped = results.groupby([\"cluster\"])\n",
    "    #fing geometric mean of the price for each cluster, and the number of observations within each cluster\n",
    "    table2015 = grouped['price'].agg({'gmean':gmean,'count':len})\n",
    "    table2015 = table2015.reset_index()\n",
    "    #sort table by the number of the cluster, not strictly neccesary but speeds up the merging later on\n",
    "    table2015.sort_values(\"cluster\",inplace=True, axis = 0)\n",
    "    #print(geobase)\n",
    "    return table2015\n",
    "\n",
    "#The geo function uses the data from the month of interest and takes the geometric mean of the prices for each cluster. \n",
    "#It then merges together the geobase results (geometric means in the base month) and the geometric means for this month and calculates a price relative across the each cluster.\n",
    "#It then weights together these clusters using the size of each cluster (in the comparison time period) as it's weight and returns the price index for that item (COICOP4 level)\n",
    "def geo(results,base):\n",
    "    grouped = results.groupby([\"cluster\"])\n",
    "    tables = grouped['price'].agg({'gmean':gmean,'count':len})\n",
    "    table = tables.reset_index()\n",
    "    table.sort_values(\"cluaster\", inplace=True, axis = 0)\n",
    "#    print(\"base clusters\")\n",
    "#    print(base)\n",
    "#    print(\"comparison clusters\")\n",
    "#    print(table)\n",
    "    table = pd.merge(base, table, how='left', on='cluster')\n",
    "#    print(\"number of clusters\")\n",
    "#    print(len(table[\"cluster\"]))\n",
    "    table[\"pr\"] = table.loc[:,'gmean_y']/table.loc[:,'gmean_x']\n",
    "    table[\"pr\"] = table[\"pr\"].fillna(1)\n",
    "    table[\"pr\"] = table.apply(lambda x: 1 if x[\"count_y\"] < (x[\"count_x\"]/4) else x[\"pr\"],axis=1)\n",
    "    print(\"merge results\")\n",
    "    print(table)\n",
    "    table.reset_index()\n",
    "    weights = np.asarray((table[\"count_x\"]).T)\n",
    "    tablepr = np.asarray(table[\"pr\"].T)\n",
    "    name1 = tablepr.dot(weights)/sum(weights)*100 \n",
    "    #print(geo)\n",
    "    return float(name1)\n",
    "\n",
    "#The Jevons is only used it only one cluster is formed by the function basetree. This implies either there is not enough data to use the CLIP approach, or that the data is already homogeneous and therefore the CLIP approach is not neccesary.\n",
    "# The Jevons is the same approach as the unit price index. This computes price relatives between the same products for each month and the base month (January). Then a geometric average of the price relatives in each COICOP4 level item is computed. This is the unit price index for each item. \n",
    "# It returns the price index at item level (COICOP4 level)\n",
    "def jevons(data,date,basedate):\n",
    "    data_base_prices = data.loc[data['monthday'].astype(int) == basedate]\n",
    "    data_comp_prices = data.loc[data['monthday'].astype(int) == date]\n",
    "    data_base_prices=data_base_prices[['product_name','price']]\n",
    "    data_base_prices.loc[:,'base_prices'] = data_base_prices.loc[:,'price']\n",
    "    data_base_prices_1=data_base_prices[['product_name','base_prices']]\n",
    "    groupedbase = data_base_prices_1.groupby(['product_name'])\n",
    "    groupbase = groupedbase['base_prices'].agg({'gmean':gmean})\n",
    "    groupedcomp = data_comp_prices.groupby('product_name')\n",
    "    groupcomp = groupedcomp['price'].agg({'gmean':gmean})\n",
    "    groupcomp.reset_index(inplace= True)\n",
    "    groupbase.reset_index(inplace =True)\n",
    "    groupbase[\"base_price\"] = groupbase[\"gmean\"]\n",
    "    groupbase=groupbase.drop(\"gmean\",1)\n",
    "    try:\n",
    "        datamerged=pd.merge(groupbase,groupcomp, how='inner', on='product_name')\n",
    "        datamerged.loc[:,'price_relative'] = datamerged.loc[:,'gmean']/datamerged.loc[:,'base_price']\n",
    "        datamerged['pr_log'] = datamerged['price_relative'].apply(math.log)\n",
    "        datamerged[\"groups\"] = 1\n",
    "        test1 = datamerged.groupby('groups')\n",
    "        lopp = test1['pr_log'].apply(np.mean).apply(np.exp)*100\n",
    "        lopp =np.array(lopp)\n",
    "        return lopp\n",
    "    except:\n",
    "        print(\"no product_name\")\n",
    "        pass\n",
    "\n",
    "def clipped(data, date, basedate,classvalue):\n",
    "    bbb = pd.DataFrame()\n",
    "    bbb.loc[:,\"index\"] = range(0,1)\n",
    "    bbb.loc[:,\"ons_name\"]= classvalue\n",
    "    basedate = int(basedate)\n",
    "    date = int(date)\n",
    "    datau = data[data[\"monthday\"].astype(int)==basedate]\n",
    "    dataa = data[data[\"monthday\"].astype(int)==date]\n",
    "    if len(dataa) == 0:\n",
    "        new = 100\n",
    "        bbb[\"type\"] = \"No data, new = 100\"\n",
    "        print(\"No data at all for this period\")\n",
    "##    print(\"len basedata\")\n",
    "##    print(len(datau))\n",
    "    #reduce dataframe to the variables that will be used within the dbscan clustering (price is included here)\n",
    "    del datau[\"ons_item_name\"]\n",
    "    del datau[\"product_name\"]\n",
    "    del datau[\"monthday\"]    \n",
    "##    print(\"reducedbase data\")\n",
    "##    print(len(datau))\n",
    "    uniquedata = datau.drop_duplicates()\n",
    " ##   print(\"unique basedata\")\n",
    "##    print(len(uniquedata))\n",
    "##    print(\"percent of unqiue\")\n",
    "##    print(len(uniquedata)/100)*nn\n",
    "    if len(uniquedata) < 30:\n",
    "        print(\"criteria\")\n",
    "        print((len(uniquedata)/100)*10)\n",
    "        # new=pd.DataFrame()\n",
    "        # new=pd.DataFrame()\n",
    "        try:\n",
    "            new = jevons(pd.DataFrame(data),date,basedate)\n",
    "            new = float(new)\n",
    "        except:\n",
    "            new =100\n",
    "            print(\"not enough data to cluster!\")\n",
    "        print(\"jevons\")\n",
    "        bbb[\"type\"] = \"Jevons\"\n",
    "    elif len(uniquedata) >=30:\n",
    "        data.loc[:, 'prod_no'] = data[\"product_name\"].apply(lambda x: fuzz.ratio(classvalue,x))\n",
    "        data.loc[:,\"prod_no\"] = (data[\"prod_no\"] - data[\"prod_no\"].mean()) / (data[\"prod_no\"].max() - data[\"prod_no\"].min())\n",
    "        bt = basetree(data,basedate)\n",
    "        if bt.n_classes_ <=2:\n",
    "            try:\n",
    "                new = jevons(pd.DataFrame(data),date,basedate)\n",
    "                new = float(new)\n",
    "            except:\n",
    "                new =100\n",
    "                print(\"not enough data!\")\n",
    "                print(\"jevons\")\n",
    "            bbb[\"type\"] = \"jevons\"\n",
    "        elif  bt.n_classes_ > 2:\n",
    "            try:\n",
    "                data2=data.drop(\"product_name\",1)\n",
    "                data2 = data2.drop(\"ons_item_name\",1)\n",
    "                if date == basedate:\n",
    "                    print(\"basemonth\")\n",
    "                    basestructure = baseclust(bt, data2,basedate)\n",
    "                    basestructure.to_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/basestructureweekly\")\n",
    "                    basedclust = applydecisiontree(data2,basedate,pd.read_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/basestructureweekly\"))\n",
    "                    basedclust.to_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/basedclustweekly\")\n",
    "                clust = applydecisiontree(data2,date,pd.read_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/basestructureweekly\"))\n",
    "                new = pd.DataFrame()\n",
    "                new = geo(clust, geobase(pd.read_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/basedclustweekly\")))\n",
    "                bbb[\"type\"] = \"CLIP\"\n",
    "            except:\n",
    "                try:\n",
    "                    new = jevons(pd.DataFrame(data),date,basedate)\n",
    "                    new = float(new)\n",
    "                except:\n",
    "                    new =100\n",
    "                    print(\"not enough data!\")\n",
    "                print(\"jevons\")\n",
    "            bbb[\"type\"] = \"CLIP\"\n",
    "        else:\n",
    "            new = \"wrong\"\n",
    "            print(\"wrong\")\n",
    "    ab= pd.read_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/metadataweek.csv\")\n",
    "    ab = ab.append(bbb)\n",
    "    print(ab)\n",
    "    del ab[\"Unnamed: 0\"]\n",
    "    ab.to_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/metadataweek.csv\")\n",
    "    return new\n",
    "\n",
    "def CLIPPEDdate(data, idvar,classvar,pricevar,datevar,basedate):\n",
    "    classvalue = np.unique(data[classvar])[0]\n",
    "    print(classvalue)\n",
    "    date = pd.DataFrame(np.unique(data[datevar]),columns=[\"dates\"]).dropna()\n",
    "    date.sort_values(by=\"dates\")\n",
    "    dates = date[\"dates\"]\n",
    "    T = len(date)\n",
    "    CLIP = date[\"dates\"].apply(lambda x:clipped(data,x,basedate,classvalue))\n",
    "    df1 = pd.DataFrame({\"i\" : range(0,len(date)),\"period\":dates,\"CLIP\":CLIP, \"ons_item_name\":classvalue})\n",
    "    df1.index = range(T)\n",
    "    return df1\n",
    "\n",
    "####monthly (updated) ########\n",
    "x = pd.read_csv('/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/averages/_week_.csv',encoding=\"latin-1\")\n",
    "x.offer = x.offer.str.encode('utf-8')\n",
    "\n",
    "#change format of the dicount/offer category\n",
    "def offer_check(dd):\n",
    "    terms = [\"buy\",\"purchase\",\"the\"]\n",
    "    for j in terms:\n",
    "        if j in dd: \n",
    "            return \"BOGO\"         \n",
    "    terms = [\"off\",\"was\",\"save\",\"half\",\"now\",\"only\"] # perhaps add,only??\n",
    "    for j in terms:\n",
    "        if j in dd:\n",
    "            return \"Discount\"\n",
    "    terms = [\"special purchase\"]\n",
    "    for j in terms:\n",
    "        if j in dd: \n",
    "            return \"Special Purchase\"\n",
    "    terms = [\"add\",\"get\"]\n",
    "    for j in terms:\n",
    "        if j in dd: \n",
    "            return \"add more\"\n",
    "    terms = [\"clear\",\"reduced\"]\n",
    "    for j in terms:\n",
    "        if j in dd:\n",
    "            return \"reduced to clear\"\n",
    "\n",
    "def produce_features(df):\n",
    "    df[\"offer\"] =df[\"offer\"].apply(lambda x: str(x))\n",
    "    df[\"offer\"] =df[\"offer\"].apply(lambda x: x.lower())\n",
    "    df[\"offer_cat\"] =df[\"offer\"].apply(lambda x: offer_check(x))\n",
    "    return df\n",
    "\n",
    "x = produce_features(x)\n",
    "\n",
    "x = x[x[\"item_price_num\"]>0]\n",
    "x[\"ons_item_name\"] = x[\"ons_item_name\"].apply(lambda x: x.strip())\n",
    "x[\"idvar\"]=x[\"product_name\"]+\"_\"+x[\"store\"]\n",
    "\n",
    "df=x[x[\"week\"]>201422]\n",
    "\n",
    "df[\"month\"]=df[\"week\"]\n",
    "#del df[\"yearweekno\"]\n",
    "\n",
    "df = man(df,\"month\")\n",
    "print(df.head(3))\n",
    "\n",
    "df14 = df[df[\"monthday\"]<201502]\n",
    "df15 = df[df[\"monthday\"]>=201501]\n",
    "df15 = df15[df15[\"monthday\"]<201602]\n",
    "df16 = df[df[\"monthday\"]>=201601]\n",
    "\n",
    "df14 = df14[df14[\"ons_item_name\"]!=\"potatoes, baking\"]\n",
    "df15 = df15[df15[\"ons_item_name\"]!=\"potatoes, baking\"]\n",
    "df16 = df16[df16[\"ons_item_name\"]!=\"potatoes, baking\"]\n",
    "\n",
    "df14 = df14[df14[\"ons_item_name\"]!=\"fizzy bottled drink\"]\n",
    "df15 = df15[df15[\"ons_item_name\"]!=\"fizzy bottled drink\"]\n",
    "df16 = df16[df16[\"ons_item_name\"]!=\"fizzy bottled drink\"]\n",
    "\n",
    "\n",
    "\n",
    "def runthrough(data,basedate):\n",
    "    a = []\n",
    "    for i in np.unique(data[\"ons_item_name\"]):\n",
    "        a.append(CLIPPEDdate(data[data[\"ons_item_name\"] == i], 'idvar', 'ons_item_name','item_price_num', 'monthday', basedate))\n",
    "    aa = np.concatenate(a, axis=0)  # axis = 1 would append things as new columns\n",
    "    aa=pd.DataFrame(aa)\n",
    "    aa.columns=[\"CLIP\",\"i\",\"ons_item_name\",\"period\"]\n",
    "\n",
    "    os.remove(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/basestructureweekly\")\n",
    "    os.remove(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/basedclustweekly\")\n",
    " \n",
    "    return aa\n",
    "\n",
    "#abweek = pd.DataFrame()\n",
    "#abweek.to_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/metadataweek.csv\")\n",
    "\n",
    "#adf = runthrough(df14, 201424)\n",
    "#adf.to_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/price_indices/CLIPweek2014.csv\")\n",
    "\n",
    "#bdf = runthrough(df15, 201501)\n",
    "#bdf.to_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/price_indices/CLIPweek2015.csv\")\n",
    "\n",
    "#cdf = runthrough(df16, 201601)\n",
    "#cdf.to_csv(\"/media/mint/e834712c-23da-4cbe-a4ec-3a35d416877b/Run_system/Data/price_indices/CLIPweek2016.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clipped(df14[df14[\"ons_item_name\"]==\"apple cider, bottle, 4.5%-5.5% abv\"], 201423, 201423,\"ons_item_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clipped(df14[df14[\"ons_item_name\"]==\"apple cider, bottle, 4.5%-5.5% abv\"], 201424, 201423,\"ons_item_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "the = df14[df14[\"ons_item_name\"]==\"apple cider, bottle, 4.5%-5.5% abv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "218"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(the[the[\"monthday\"]==201423])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(the.drop_duplicates(\"product_name\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>ons_item_name</th>\n",
       "      <th>monthday</th>\n",
       "      <th>price</th>\n",
       "      <th>SAINSBURY</th>\n",
       "      <th>TESCO</th>\n",
       "      <th>WAITROSE</th>\n",
       "      <th>sainsbury</th>\n",
       "      <th>tesco</th>\n",
       "      <th>waitrose</th>\n",
       "      <th>BOGO</th>\n",
       "      <th>Discount</th>\n",
       "      <th>add more</th>\n",
       "      <th>reduced to clear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>addlestones cider 500ml_sainsbury</td>\n",
       "      <td>apple cider, bottle, 4.5%-5.5% abv</td>\n",
       "      <td>201423.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>addlestones cider 500ml_sainsbury</td>\n",
       "      <td>apple cider, bottle, 4.5%-5.5% abv</td>\n",
       "      <td>201424.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>addlestones cider 500ml_sainsbury</td>\n",
       "      <td>apple cider, bottle, 4.5%-5.5% abv</td>\n",
       "      <td>201425.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           product_name                       ons_item_name  \\\n",
       "5264  addlestones cider 500ml_sainsbury  apple cider, bottle, 4.5%-5.5% abv   \n",
       "5265  addlestones cider 500ml_sainsbury  apple cider, bottle, 4.5%-5.5% abv   \n",
       "5266  addlestones cider 500ml_sainsbury  apple cider, bottle, 4.5%-5.5% abv   \n",
       "\n",
       "      monthday  price  SAINSBURY  TESCO  WAITROSE  sainsbury  tesco  waitrose  \\\n",
       "5264  201423.0    2.0        0.0    0.0       0.0        1.0    0.0       0.0   \n",
       "5265  201424.0    2.0        0.0    0.0       0.0        1.0    0.0       0.0   \n",
       "5266  201425.0    2.0        0.0    0.0       0.0        1.0    0.0       0.0   \n",
       "\n",
       "      BOGO  Discount  add more  reduced to clear  \n",
       "5264   0.0       0.0       0.0               0.0  \n",
       "5265   0.0       0.0       0.0               0.0  \n",
       "5266   0.0       0.0       0.0               0.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "the.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
